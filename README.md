<p align='center'>
<img src="https://capsule-render.vercel.app/api?type=cylinder&height=200&color=2c2c2a&text=Autonomous-Mobile-Logistics-Robot&section=header&textBg=false&fontColor=FFFFFF&fontAlign=50&fontAlignY=40&fontSize=40&desc=Including-Towing-Capability&stroke=3-Axis-Cartesian-Robot%20&descAlignY=65&descSize=20" />

<div align="center">
<h2>[2025] 견인기능을 포함한 물류로봇 </h2>
본 시스템은 고장 로봇 발생 시 별도의 인력 개입 없이 작업 흐름을 유지할 수 있도록 하여 다운타임을 감소시키고, 운영 비용 절감과 처리 효율 향상을 가능하게 한다. 더 나아가 로봇 간 협업 기반 자동 복구 체계를 구축함으로써 물류 시스템의 복원 탄력성과 고가용성 확보에 기여하며, 스마트 물류센터 및 무인 물류 환경으로의 확장 가능성을 제공한다.
</div>

## 목차
  - [개요](#개요) 
  - [작품 설명](#작품-설명)
  - [작품 작동 방식](#작품-작동-방식)
  - [역할 및 내용](#역할-및-내용)
  - [트러블 슈팅](#트러블-슈팅)
  - [코멘트](#코멘트)

## 개요
- 프로젝트 이름: 견인기능을 포함한 물류로봇
- 프로젝트 기간: 2025.01-2025.12
- 개발 엔진 및 언어: C & C++ & Python 
- 멤버: Interface (이윤승 ,박승규 ,최성원 ,김혁진)

## 작품 설명
본 작품은 자율이동로봇(AMR) 환경에서 고장 로봇을 정상 로봇이 자율적으로 인식하고 도킹·견인하여 물류 작업 흐름을 유지하는 자동 복구형 협업 로봇 시스템이다. 다중 센서 융합 기반 정렬 및 결합 메커니즘과 견인 모드 전환에 따른 제어 파라미터 자동 조정을 통해 하중 변화에 안정적으로 대응할 수 있도록 설계되었다. 이를 통해 물류센터 내 작업 중단을 최소화하고 운영 안정성과 고가용성을 확보한다.

## 작품 작동 방식
<img width="640" height="480" alt="image" src="https://github.com/user-attachments/assets/c358708f-4f65-433b-838a-32cf11c9d10c" />

https://youtu.be/UkVe2rLXZ-U<br>

또는 demonstration video참조<br>

## 역할 및 내용

<table align="center">
  <thead>
    <tr>
      <th align="center">이름</th>
      <th align="center">역할</th>
      <th align="center">내용</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td nowrap align="center">이윤승</td>
      <td align="center">프로젝트 총괄<br>견인 시 주행 안정화 알고리즘 개발<br>멀티로봇 시스템 개발<br>관제 시스템 개발</td>
      <td align="center">견인 시 주행 불안정성 완화를 위한 알고리즘 개발<br>멀티 로봇 제어를 위한 환경 구축<br>멀티로봇의 작업 스케쥴러 생성<br>관제시스템 UI 제작</td>
    </tr>
    <tr>
      <td nowrap align="center">박승규</td>
      <td align="center">모터 제어<br>센서 데이터 수집</td>
      <td align="center">STM32 기반 엔코더 속도 측정 및 모터 PWM 제어 루프 구현<br>목표 선속도/각속도 추종을 위한 증분형 PID 제어기 적용<br>견인/비견인 모드 전환 시 PID 게인 자동 스위칭 구조 설계<br>엔코더 값을 이용해 Dead-reckoning 오도메트리로 (x, y, yaw) 위치를 추정<br>IMU + 2D LiDAR EKF 융합으로 장기 드리프트 보정</td>
    </tr>
    <tr>
      <td nowrap align="center">최성원</td>
      <td align="center">영상인식 장치 제작<br>자율주행 알고리즘 개발<br>로봇정렬</td>
      <td align="center">카메라 기반 영상 인식 장치 설계 및 ROS2 연동, 로봇 전방 환경 및<br> 도킹 대상 인식을 위한 영상 처리 파이프라인 구성<br>
영상 인식 결과를 이용한 로봇 정렬 알고리즘 설계<br>
목표 위치·각도 오차에 따른 단계적 접근 로직 구성</td>
    </tr>
    <tr>
      <td nowrap align="center">김혁진</td>
      <td align="center">외관 제작<br>내부 설계 제작<br>회로도 제작<br>센서 데이터 수집</td>
      <td align="center">3D프린터를 이용한 외관제작<br>소자간의 밀집도가 높은 회로도 제작<br>회로도, 베터리, 젯슨오린나노 등 모듈간의 밀집도높은 내부 설계</td>
    </tr>
  </tbody>
</table>

## 트러블 슈팅
- **견인 모드에서 주행 불안정(피시테일) 발생**
  - 문제: 고장 로봇을 견인해 안전/정비 구역으로 이동 중, 피시테일이 발생하여 경로를 이탈함.
  - 원인: 견인 하중이 후방에 집중되면서 yaw 관성 및 응답 지연이 증가해, 기존 경로추종 제어에서 회전 오버슈트가 반복적으로 증폭됨.
  - 해결: 경로 상 2개 예측점으로 목표 방향각(heading angle)을 atan2 기반으로 계산하고, 목표 방향각(heading angle)이 임계각과 비교하여 초과하면 선속도를 제한한 뒤 각속도 우선으로 heading을
          먼저 정렬하고, 정렬 완료 후 경로 추종을 재개하도록 제어 로직을 분기함.
  - 결과: 동일 조건 반복 시험에서 경로 평균 오차가 0.4 m → 0.1 m로 감소함.
 
- **로봇의 크기와 무게 문제**
  - 문제: 로봇의 크기와 무게가 예상보다 커 줄일 필요가 생겼습니다.
  - 원인: 필요이상의 많은 소자를 사용하고 소자간의 밀집도가 떨어져 로봇 모델의 크기가 커졌습니다.
  - 해결: 중요도가 떨어지는 소자를 줄이고 소자간의 밀집도를 중심으로 재설계를 했습니다.
  - 결과: 로봇 모델의 무게를 10 ~ 11kg에서 7kg로 줄이고 크기도 줄였습니다.
 
- **후크모양에서 생기는 전류문제**
  - 문제: 견인이 성공하는 구역을 넓게하고 피견인 로봇을 높게 들게 설계를 할시 엑추에이터가 너무 많은 전류를 필요로하는 문제가 생겼습니다.
  - 원인: 2개의 엑추에이터에서 견인을 하는것을 1개의 지지대와 1개의 엑추에이터로 견인을 하게 재설계를 하여 문제가 발생하였습니다.
  - 해결: 후크구조에 임의로 3가지 정도 변수를 만들어 그 3가지의 변수를 조절하며 최적의 후크구조를 찾아 해결하였습니다.
  - 결과: 최대 전류 0.1A로 견인을 할수있게 되었습니다.

- **견인 모드 하중 변화로 인한 주행 오차 증가**
  - **문제:** 견인 상태에서 속도·자세(heading) 오차가 커지며 경로 추종 안정성이 저하됨
  - **원인:** 견인 하중 증가로 시스템 동특성(관성/저항)이 변해 기존 PID 이득으로는 추종 성능이 부족함
  - **해결:** **견인 모드 전용 PID 제어 이득을 재조정(튜닝)**하고, 견인/비견인 모드에 따라 이득을 분리 적용
  - **결과:** 견인 주행 시 속도·자세 오차가 감소하고 경로 추종이 안정화됨

- **Dead-reckoning 기반 오도메트리 누적 드리프트**
  - **문제:** 장시간 주행 시 (x, y, yaw) 추정값이 누적 오차로 인해 실제 위치와 점점 벌어짐
  - **원인:** 엔코더 기반 Dead-reckoning은 슬립, 노면 변화, 엔코더/시간 동기 오차가 누적되어 장기 드리프트가 발생함
  - **해결:** IMU + 2D LiDAR를 EKF로 융합하여 오도메트리 예측값을 센서 측정으로 주기적으로 보정
  - **결과:** 장기 드리프트가 억제되어 위치추정 신뢰도가 향상되고 도킹/견인 시 정렬 안정성이 개선됨

  **영상 인식 기반 로봇 정렬 오차 및 인식 불안정성**
  - 문제: 조명·각도·가림(occlusion) 영향으로 영상 인식 기반 상대 위치/각도 추정이 흔들려 도킹 정렬이 불안정해짐

  - 원인: 단일 카메라 인식은 환경 변화에 민감하고 프레임 간 추정값이 튀어 제어 입력이 급격히 변할 수 있음

  - 해결: 영상 인식 결과를 정렬 목표값으로 사용하되 레이저 센서 등 보조 정보로 제어를 안정화하고 인식 노이즈를 완화

  - 결과: 인식 불안정이 줄어 정렬 성공률이 향상되고 도킹/견인 단계 결합 신뢰도가 개선됨
  
## 코멘트

- PID 게인을 실험적으로 조정해 성능을 맞췄지만, 시간·환경 제약으로 충분한 반복 실험 데이터를 쌓지 못한 점이 아쉬웠습니다. 다음에는 더 다양한 조건에서 데이터를 축적해 근거 기반으로 최적 게인을 도출하고 싶습니다.
- 너무 회로도와 내부 설계 밀집도만 집중해서 내부온도와 같이 중요한 부분을 놓친게 많아 아쉽다.
- 게인과 임계값을 경험적으로 맞춰 동작은 확보했지만, 하중/바닥 마찰/배터리 전압 변화까지 포함한 체계적인 튜닝 실험과 데이터 기반 최적화가 부족했다. 동일 조건 반복 실험을 통해 최적의 게인 값을 구하여 로봇이 안정적이게 움직일 수 있도록 시도 해 볼 가치가 있다.
- ArUco 마커 기반 인식은 정렬 정확도가 높고 구현이 간단하다는 장점이 있으나, 마커 훼손·가림·부착 관리가 필요한 구조적 한계가 있다. 본 연구에서는 해당 방식에 의존하였다는 점에서 실제 현장 적용성을 충분히 고려하지 못한 아쉬움이 있다. 향후에는 로봇의 형상과 외관 특징을 학습한 객체 인식 모델을 활용하여 마커 없는 정렬 방식을 적용함으로써 시스템의 실용성과 확장성을 높이고자 한다.
- 실물 로봇을 만들기전에 Gazebo 시뮬레이션을 사용해보고 했으면 시행착오가 덜 했을것 같다는 생각이 들었다 다음에는 시뮬레이션을 돌려보고 실물 로봇 제작을 해야할것 같다.
- 생각보다 C/C++/Python을 사용을 잘 못하는 것 같다 코딩 테스트나 공부를 더해야겠다는 생각이 들었다.
- 내가 만든 알고리즘을 논문이나 발표자료에 수식으로 표현해야하는데 수학적인 지식이 부족해서 표현하는데 힘들었던 것 같다 선형대수학과 미적분학, 확률과 통계에 대한 공부를 더 해야겠다는 생각이 들었다
